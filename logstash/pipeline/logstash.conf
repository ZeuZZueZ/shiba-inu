input {
	file { 
		path => "/usr/share/logstash/tmp/log*"
		start_position => "beginning"
	}
}

filter {
	## discovery

	grok {
		patterns_dir => ["./patterns"]
		match => {
			message =>  "^%{IP:clientip} (?<handle>(HTTP:HDL)) %{QS:timestamp} %{INT:ld} %{INT:lds} (?<ms>((.+ms))) %{DOI:doi} %{QS:server} %{QS:something} %{QS:user_agent}"
		}
		add_tag => ["grooked"]
	}

	##### Structuring
	# grok {
	# 	patterns_dir => ["./patterns"]
	# 	match => { "message" => "%{DOI:doi}" }
	#   add_tag =>["doiable"]
	# }
	## "%{HANDLE:log_type}" "%{DATACITE:server_nyame}"

  # mutate {
  #   replace => { "message" => "%{server_nyame}: datacite" }
  # }

	## cleaning
	# if [event][server_name] != "datacite" {
  #   drop { }
  # }

	## Enriching

	geoip {
		source => "clientip"
	}

  rest {
    request => {
      url => "https://api.datacite.org/works?id=10.25499/ps2xm5sm3boovgtrayjunhugbb"        
      method => "get"                 
      # params => {                       
      #   "id" => "%{doi}"
      # }
    }
    json => true                         # boolean (optional, default = true)
    target => "dc_metadata"                   # string (mandatory, no default)
    fallback => {                        # hash describing a default in case of error
      'fallback1' => true
    }
  }


	## Publishing
}
output {
	if "_grokparsefailure" in [tags] {
    #### write events that didn't match to a file
    file { "path" => "/tmp/grok_failures.txt" }
  } else {
		elasticsearch { hosts => ["elasticsearch:9200"] }
		stdout { codec => rubydebug }
	}
}

